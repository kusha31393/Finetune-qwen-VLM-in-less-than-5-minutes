{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMoshLuJbx8+YJlH8FmfXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kusha31393/Finetune_qwen2.5_VL/blob/main/finetune_qwen_vl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-0hIiFnWuKm"
      },
      "outputs": [],
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastVisionModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "hGvAgjm7Xi9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourbit_models = [\n",
        "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n",
        "]"
      ],
      "metadata": {
        "id": "GK4DIQYSYV11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    use_gradient_checkpointing=\"unsloth\"\n",
        ")"
      ],
      "metadata": {
        "id": "I4gq8XxoZEiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers=True,\n",
        "    finetune_language_layers=True,\n",
        "    finetune_attention_modules=True,\n",
        "    finetune_mlp_modules=True,\n",
        "\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None\n",
        ")"
      ],
      "metadata": {
        "id": "NEJoJwTHZx0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"unsloth/Latex_OCR\", split=\"train\")"
      ],
      "metadata": {
        "id": "4jwTPR23NcrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "LSwccvVvNqbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "WNQbjjTvNzue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['image']"
      ],
      "metadata": {
        "id": "Ssvvj0WyN1tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[42837]['image']"
      ],
      "metadata": {
        "id": "h00pkEbgN5Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[42837]['text']"
      ],
      "metadata": {
        "id": "iKgGtJbNN9_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Write the LaTex representation for this image.\""
      ],
      "metadata": {
        "id": "1Rj7qdEyOSYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_conversation(sample):\n",
        "  conversation = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": instruction},\n",
        "              {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
        "          ]\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": sample[\"text\"]}\n",
        "          ]\n",
        "      }\n",
        "\n",
        "  ]\n",
        "  return {\"messages\": conversation}"
      ],
      "metadata": {
        "id": "7CADYD2YOfXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_conversation(dataset[0])"
      ],
      "metadata": {
        "id": "LIbcJ9AZPCUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
      ],
      "metadata": {
        "id": "ysQWCMqMPGFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_dataset[1]"
      ],
      "metadata": {
        "id": "OVJYjs8FPN0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "id": "bzd0hyPPPiJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = dataset[1][\"image\"]\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": instruction},\n",
        "            {\"type\": \"image\", \"image\": image}\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "5c0EP0qgRXF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = tokenizer(\n",
        "    image, input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "rQa47wbiSMlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128, use_cache=True, temperature=1.5, min_p=0.1)"
      ],
      "metadata": {
        "id": "geJD2iYDSvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "TgGfoacYTd04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bf16_supported\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig"
      ],
      "metadata": {
        "id": "-yAVs8XdTqlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "id": "eGNZrNk7Y9BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=UnslothVisionDataCollator(model, tokenizer),\n",
        "    train_dataset=converted_dataset,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=30,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "        remove_unused_columns=False,\n",
        "        dataset_text_field=\"\",\n",
        "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc=4,\n",
        "        max_seq_length=2048,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "DQXs1y-MZCYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "ke8kKn49cBqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastVisionModel.for_inference(model)"
      ],
      "metadata": {
        "id": "22vJWWIAcKk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = dataset[2][\"image\"]"
      ],
      "metadata": {
        "id": "Fm2Zhm9_chfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Write the LateX representation for this image.\""
      ],
      "metadata": {
        "id": "3NzfCOp1clBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]"
      ],
      "metadata": {
        "id": "liuY8RwjcqK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens=False,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "mr3ZZSzHc74W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128, use_cache=True, temperature=1.5, min_p=0.1)"
      ],
      "metadata": {
        "id": "FBoX4a07dPkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "cDwjfXJWdnUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qaJYcR7Fdqdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}